import { useState, useEffect, useRef } from 'react';
import { Platform, Alert } from 'react-native';
import { Audio } from 'expo-av';

interface RecordingState {
  isRecording: boolean;
  isPaused: boolean;
  duration: number;
  uri: string | null;
}

interface WebRecordingState {
  mediaRecorder: MediaRecorder | null;
  audioChunks: Blob[];
  stream: MediaStream | null;
}

interface TranscriptionResult {
  text: string;
  language: string;
}

interface UseAudioRecordingProps {
  onTranscriptionComplete?: (text: string) => void;
  onError?: (error: string) => void;
  processVoiceCommands?: (text: string) => string;
}

export const useAudioRecording = ({
  onTranscriptionComplete,
  onError,
  processVoiceCommands,
}: UseAudioRecordingProps = {}) => {
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [webRecording, setWebRecording] = useState<WebRecordingState>({
    mediaRecorder: null,
    audioChunks: [],
    stream: null,
  });
  const [recordingState, setRecordingState] = useState<RecordingState>({
    isRecording: false,
    isPaused: false,
    duration: 0,
    uri: null,
  });
  const [isTranscribing, setIsTranscribing] = useState<boolean>(false);
  const [isRecordingUnloaded, setIsRecordingUnloaded] = useState<boolean>(false);
  
  const durationIntervalRef = useRef<ReturnType<typeof setInterval> | undefined>(undefined);

  useEffect(() => {
    if (recordingState.isRecording && !recordingState.isPaused) {
      durationIntervalRef.current = setInterval(() => {
        setRecordingState(prev => ({ ...prev, duration: prev.duration + 1 }));
      }, 1000);
    } else {
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
      }
    }

    return () => {
      if (durationIntervalRef.current) {
        clearInterval(durationIntervalRef.current);
      }
    };
  }, [recordingState.isRecording, recordingState.isPaused]);

  useEffect(() => {
    const cleanupOnUnmount = async () => {
      if (Platform.OS === 'web') {
        if (webRecording.mediaRecorder && webRecording.mediaRecorder.state === 'recording') {
          webRecording.mediaRecorder.stop();
        }
        if (webRecording.stream) {
          webRecording.stream.getTracks().forEach(track => track.stop());
        }
      } else {
        if (recording && !isRecordingUnloaded) {
          try {
            await recording.stopAndUnloadAsync();
          } catch (error) {
            console.error('Error during cleanup:', error);
          }
        }
      }
    };

    return () => {
      cleanupOnUnmount();
    };
  }, [recording, isRecordingUnloaded, webRecording]);

  const cleanup = async () => {
    if (Platform.OS === 'web') {
      if (webRecording.mediaRecorder && webRecording.mediaRecorder.state === 'recording') {
        webRecording.mediaRecorder.stop();
      }
      if (webRecording.stream) {
        webRecording.stream.getTracks().forEach(track => track.stop());
      }
    } else {
      if (recording && !isRecordingUnloaded) {
        try {
          await recording.stopAndUnloadAsync();
        } catch (error) {
          console.error('Error during cleanup:', error);
        }
      }
    }
  };

  const requestPermissions = async (): Promise<boolean> => {
    try {
      if (Platform.OS === 'web') {
        console.log('üåê Solicitando permisos de micr√≥fono web...');
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        console.log('‚úÖ Permisos web concedidos');
        return true;
      } else {
        console.log('üì± Solicitando permisos de micr√≥fono m√≥vil...');
        const { status, granted } = await Audio.requestPermissionsAsync();
        console.log('üì± Estado de permisos:', status, 'granted:', granted);
        if (granted) {
          console.log('‚úÖ Permisos m√≥vil concedidos');
        } else {
          console.log('‚ùå Permisos m√≥vil denegados');
        }
        return granted;
      }
    } catch (error) {
      console.error('‚ùå Error solicitando permisos:', error);
      return false;
    }
  };

  const transcribeAudioFromBlob = async (audioBlob: Blob): Promise<void> => {
    setIsTranscribing(true);
    
    try {
      console.log('üé§ Transcribiendo audio web:', {
        size: audioBlob.size,
        type: audioBlob.type
      });
      
      if (audioBlob.size === 0) {
        throw new Error('Audio vac√≠o - no se grab√≥ contenido');
      }
      
      if (audioBlob.size < 1000) {
        console.warn('Audio muy peque√±o:', audioBlob.size, 'bytes');
        if (Platform.OS === 'web') {
          alert('El audio es muy corto. Intenta grabar por m√°s tiempo.');
        } else {
          Alert.alert('Aviso', 'El audio es muy corto. Intenta grabar por m√°s tiempo.');
        }
        return;
      }
      
      const formData = new FormData();
      
      let fileName = 'recording.webm';
      if (audioBlob.type.includes('mp4')) {
        fileName = 'recording.mp4';
      } else if (audioBlob.type.includes('wav')) {
        fileName = 'recording.wav';
      }
      
      formData.append('audio', audioBlob, fileName);
      
      console.log('üì§ Enviando a transcripci√≥n:', fileName, audioBlob.size, 'bytes');
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
        console.log('‚è∞ Timeout de transcripci√≥n');
      }, 30000);
      
      const response = await fetch('https://toolkit.rork.com/stt/transcribe/', {
        method: 'POST',
        body: formData,
        signal: controller.signal,
      });
      
      clearTimeout(timeoutId);
      
      console.log('üì• Respuesta transcripci√≥n:', response.status, response.statusText);
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Error respuesta:', response.status, errorText);
        
        if (response.status === 413) {
          throw new Error('El archivo de audio es demasiado grande');
        } else if (response.status === 415) {
          throw new Error('Formato de audio no soportado');
        } else if (response.status >= 500) {
          throw new Error('Error del servidor. Intenta de nuevo en unos momentos');
        } else {
          throw new Error(`Error ${response.status}: ${errorText || 'Error desconocido'}`);
        }
      }
      
      const result: TranscriptionResult = await response.json();
      console.log('‚úÖ Transcripci√≥n completada:', {
        text: result.text?.substring(0, 100) + '...',
        language: result.language,
        length: result.text?.length
      });
      
      if (!result.text || result.text.trim() === '') {
        console.warn('‚ö†Ô∏è Transcripci√≥n vac√≠a');
        if (Platform.OS === 'web') {
          alert('No se detect√≥ texto claro en el audio. Intenta hablar m√°s cerca del micr√≥fono.');
        } else {
          Alert.alert('Aviso', 'No se detect√≥ texto claro en el audio. Intenta hablar m√°s cerca del micr√≥fono.');
        }
        return;
      }
      
      const rawText = result.text.trim();
      const processedText = processVoiceCommands ? processVoiceCommands(rawText) : rawText;
      
      console.log('Raw text:', rawText);
      console.log('Processed text:', processedText);
      
      if (onTranscriptionComplete) {
        onTranscriptionComplete(processedText);
      }
      
      console.log('‚ú® Texto agregado exitosamente');
    } catch (error) {
      console.error('‚ùå Error transcripci√≥n:', error);
      
      const errorMessage = error instanceof Error && error.name === 'AbortError'
        ? 'La transcripci√≥n est√° tomando demasiado tiempo. Verifica tu conexi√≥n e intenta de nuevo.'
        : error instanceof Error ? error.message : 'Error desconocido al transcribir el audio';
      
      if (onError) {
        onError(errorMessage);
      }
      
      if (Platform.OS === 'web') {
        alert(errorMessage);
      } else {
        Alert.alert('Error de Transcripci√≥n', errorMessage);
      }
    } finally {
      setIsTranscribing(false);
    }
  };

  const transcribeAudioFromUri = async (uri: string): Promise<void> => {
    setIsTranscribing(true);
    
    try {
      console.log('üì± Transcribiendo desde m√≥vil:', uri);
      
      if (!uri) {
        throw new Error('URI de audio no v√°lida');
      }
      
      const formData = new FormData();
      const uriParts = uri.split('.');
      const fileType = uriParts[uriParts.length - 1];
      
      const audioFile = {
        uri,
        name: `recording.${fileType}`,
        type: `audio/${fileType}`,
      } as any;
      
      formData.append('audio', audioFile);
      
      console.log('üì§ Enviando archivo m√≥vil:', audioFile.name, 'tipo:', audioFile.type);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
        console.log('‚è∞ Timeout de transcripci√≥n m√≥vil');
      }, 30000);
      
      const response = await fetch('https://toolkit.rork.com/stt/transcribe/', {
        method: 'POST',
        body: formData,
        signal: controller.signal,
      });
      
      clearTimeout(timeoutId);
      
      console.log('üì• Respuesta m√≥vil:', response.status, response.statusText);
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Error respuesta m√≥vil:', response.status, errorText);
        
        if (response.status === 413) {
          throw new Error('El archivo de audio es demasiado grande');
        } else if (response.status === 415) {
          throw new Error('Formato de audio no soportado');
        } else if (response.status >= 500) {
          throw new Error('Error del servidor. Intenta de nuevo en unos momentos');
        } else {
          throw new Error(`Error ${response.status}: ${errorText || 'Error desconocido'}`);
        }
      }
      
      const result: TranscriptionResult = await response.json();
      console.log('‚úÖ Transcripci√≥n m√≥vil completada:', {
        text: result.text?.substring(0, 100) + '...',
        language: result.language,
        length: result.text?.length
      });
      
      if (!result.text || result.text.trim() === '') {
        console.warn('‚ö†Ô∏è Transcripci√≥n m√≥vil vac√≠a');
        if (Platform.OS === 'web') {
          alert('No se detect√≥ texto claro en el audio. Intenta hablar m√°s cerca del micr√≥fono.');
        } else {
          Alert.alert('Aviso', 'No se detect√≥ texto claro en el audio. Intenta hablar m√°s cerca del micr√≥fono.');
        }
        return;
      }
      
      const rawText = result.text.trim();
      const processedText = processVoiceCommands ? processVoiceCommands(rawText) : rawText;
      
      console.log('Raw text:', rawText);
      console.log('Processed text:', processedText);
      
      if (onTranscriptionComplete) {
        onTranscriptionComplete(processedText);
      }
      
      console.log('‚ú® Transcripci√≥n m√≥vil agregada exitosamente');
    } catch (error) {
      console.error('‚ùå Error transcripci√≥n m√≥vil:', error);
      
      const errorMessage = error instanceof Error && error.name === 'AbortError'
        ? 'La transcripci√≥n est√° tomando demasiado tiempo. Verifica tu conexi√≥n e intenta de nuevo.'
        : error instanceof Error ? error.message : 'Error desconocido al transcribir el audio';
      
      if (onError) {
        onError(errorMessage);
      }
      
      if (Platform.OS === 'web') {
        alert(errorMessage);
      } else {
        Alert.alert('Error de Transcripci√≥n', errorMessage);
      }
    } finally {
      setIsTranscribing(false);
    }
  };

  const startRecording = async (): Promise<boolean> => {
    try {
      console.log('Iniciando grabaci√≥n...');
      
      const hasPermission = await requestPermissions();
      if (!hasPermission) {
        const errorMsg = 'Se requieren permisos de micr√≥fono.';
        if (onError) onError(errorMsg);
        if (Platform.OS === 'web') {
          alert(errorMsg);
        } else {
          Alert.alert('Error', errorMsg);
        }
        return false;
      }

      if (Platform.OS === 'web') {
        console.log('üåê Iniciando grabaci√≥n web...');
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 48000,
          } 
        });
        
        console.log('üì° Stream obtenido:', stream.getTracks().length, 'pistas');
        
        let mimeType = 'audio/webm;codecs=opus';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/webm';
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/mp4';
            if (!MediaRecorder.isTypeSupported(mimeType)) {
              mimeType = 'audio/ogg;codecs=opus';
            }
          }
        }
        
        console.log('üéµ Usando formato:', mimeType, 'soportado:', MediaRecorder.isTypeSupported(mimeType));
        
        const options: MediaRecorderOptions = { 
          mimeType,
          audioBitsPerSecond: 128000,
        };
        
        const mediaRecorder = new MediaRecorder(stream, options);
        const localAudioChunks: Blob[] = [];
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data && event.data.size > 0) {
            console.log('üì¶ Chunk recibido:', event.data.size, 'bytes, tipo:', event.data.type);
            localAudioChunks.push(event.data);
          } else {
            console.warn('‚ö†Ô∏è Chunk vac√≠o recibido');
          }
        };
        
        mediaRecorder.onstop = async () => {
          console.log('üõë Grabaci√≥n web detenida, procesando...');
          console.log('üì¶ Chunks totales:', localAudioChunks.length);
          
          if (localAudioChunks.length === 0) {
            console.error('‚ùå No se recibieron chunks de audio');
            if (Platform.OS === 'web') {
              alert('No se grab√≥ ning√∫n audio. Verifica que el micr√≥fono est√© funcionando.');
            } else {
              Alert.alert('Error', 'No se grab√≥ ning√∫n audio. Verifica que el micr√≥fono est√© funcionando.');
            }
            stream.getTracks().forEach(track => track.stop());
            return;
          }
          
          const audioBlob = new Blob(localAudioChunks, { type: mimeType });
          
          console.log('üéµ Audio blob creado:', {
            size: audioBlob.size,
            type: audioBlob.type,
            chunks: localAudioChunks.length
          });
          
          if (audioBlob.size > 0) {
            await transcribeAudioFromBlob(audioBlob);
          } else {
            console.warn('‚ö†Ô∏è Audio vac√≠o, no se puede transcribir');
            if (Platform.OS === 'web') {
              alert('No se detect√≥ audio para transcribir.');
            } else {
              Alert.alert('Aviso', 'No se detect√≥ audio para transcribir.');
            }
          }
          
          console.log('üîá Deteniendo pistas de audio...');
          stream.getTracks().forEach(track => {
            console.log('Deteniendo pista:', track.kind, track.label);
            track.stop();
          });
        };
        
        mediaRecorder.onerror = (event) => {
          console.error('Error en MediaRecorder:', event);
          if (Platform.OS === 'web') {
            alert('Error durante la grabaci√≥n.');
          } else {
            Alert.alert('Error', 'Error durante la grabaci√≥n.');
          }
        };
        
        setWebRecording({
          mediaRecorder,
          audioChunks: localAudioChunks,
          stream,
        });
        
        mediaRecorder.start(100);
        
        console.log('‚ñ∂Ô∏è MediaRecorder iniciado, estado:', mediaRecorder.state);
        
        setRecordingState({
          isRecording: true,
          isPaused: false,
          duration: 0,
          uri: null,
        });
        
        console.log('‚úÖ Grabaci√≥n web iniciada correctamente');
        return true;
      } else {
        console.log('üì± Configurando modo de audio m√≥vil...');
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: true,
          playsInSilentModeIOS: true,
          staysActiveInBackground: false,
        });

        console.log('üéôÔ∏è Creando grabaci√≥n m√≥vil...');
        const recordingOptions: Audio.RecordingOptions = {
          android: {
            extension: '.m4a',
            outputFormat: Audio.AndroidOutputFormat.MPEG_4,
            audioEncoder: Audio.AndroidAudioEncoder.AAC,
            sampleRate: 44100,
            numberOfChannels: 2,
            bitRate: 128000,
          },
          ios: {
            extension: '.m4a',
            outputFormat: Audio.IOSOutputFormat.MPEG4AAC,
            audioQuality: Audio.IOSAudioQuality.HIGH,
            sampleRate: 44100,
            numberOfChannels: 2,
            bitRate: 128000,
          },
          web: {
            mimeType: 'audio/webm',
            bitsPerSecond: 128000,
          },
        };
        
        console.log('üéôÔ∏è Opciones de grabaci√≥n:', JSON.stringify(recordingOptions, null, 2));
        
        const { recording: newRecording, status } = await Audio.Recording.createAsync(
          recordingOptions
        );
        
        console.log('üì± Estado de grabaci√≥n:', status);
        console.log('‚úÖ Grabaci√≥n m√≥vil creada');
        
        setRecording(newRecording);
        setIsRecordingUnloaded(false);
        setRecordingState({
          isRecording: true,
          isPaused: false,
          duration: 0,
          uri: null,
        });
        
        console.log('‚úÖ Grabaci√≥n m√≥vil iniciada correctamente');
        return true;
      }
    } catch (error) {
      console.error('Error al iniciar grabaci√≥n:', error);
      const errorMsg = `No se pudo iniciar la grabaci√≥n: ${error instanceof Error ? error.message : 'Error desconocido'}`;
      if (onError) onError(errorMsg);
      if (Platform.OS === 'web') {
        alert(errorMsg);
      } else {
        Alert.alert('Error', errorMsg);
      }
      return false;
    }
  };

  const stopRecording = async (): Promise<void> => {
    try {
      console.log('Deteniendo grabaci√≥n...');
      
      setRecordingState(prev => ({
        ...prev,
        isRecording: false,
        isPaused: false,
      }));
      
      if (Platform.OS === 'web') {
        console.log('üõë Deteniendo grabaci√≥n web, estado:', webRecording.mediaRecorder?.state);
        if (webRecording.mediaRecorder && webRecording.mediaRecorder.state !== 'inactive') {
          webRecording.mediaRecorder.stop();
          console.log('‚úÖ MediaRecorder detenido');
        } else {
          console.warn('‚ö†Ô∏è MediaRecorder no est√° activo o no existe');
        }
      } else {
        console.log('üõë Deteniendo grabaci√≥n m√≥vil...');
        if (!recording || isRecordingUnloaded) {
          console.log('‚ö†Ô∏è No hay grabaci√≥n activa');
          return;
        }
        
        console.log('üì± Obteniendo URI y deteniendo...');
        const uri = recording.getURI();
        console.log('üìç URI:', uri);
        
        await recording.stopAndUnloadAsync();
        setIsRecordingUnloaded(true);
        
        console.log('üîá Desactivando modo de grabaci√≥n...');
        await Audio.setAudioModeAsync({
          allowsRecordingIOS: false,
        });
        
        console.log('‚úÖ Grabaci√≥n m√≥vil guardada:', uri);
        setRecording(null);
        
        if (uri) {
          await transcribeAudioFromUri(uri);
        } else {
          console.error('‚ùå URI de grabaci√≥n es nulo');
        }
      }
    } catch (error) {
      console.error('Error al detener grabaci√≥n:', error);
      setRecording(null);
      setIsRecordingUnloaded(true);
      const errorMsg = 'Error al detener la grabaci√≥n.';
      if (onError) onError(errorMsg);
      if (Platform.OS === 'web') {
        alert(errorMsg);
      } else {
        Alert.alert('Error', errorMsg);
      }
    }
  };

  const pauseRecording = async (): Promise<void> => {
    try {
      if (Platform.OS === 'web') {
        if (webRecording.mediaRecorder && webRecording.mediaRecorder.state === 'recording') {
          webRecording.mediaRecorder.pause();
          setRecordingState(prev => ({ ...prev, isPaused: true }));
        }
      } else {
        if (recording) {
          await recording.pauseAsync();
          setRecordingState(prev => ({ ...prev, isPaused: true }));
        }
      }
    } catch (error) {
      console.error('Error pausing recording:', error);
    }
  };

  const resumeRecording = async (): Promise<void> => {
    try {
      if (Platform.OS === 'web') {
        if (webRecording.mediaRecorder && webRecording.mediaRecorder.state === 'paused') {
          webRecording.mediaRecorder.resume();
          setRecordingState(prev => ({ ...prev, isPaused: false }));
        }
      } else {
        if (recording) {
          await recording.startAsync();
          setRecordingState(prev => ({ ...prev, isPaused: false }));
        }
      }
    } catch (error) {
      console.error('Error resuming recording:', error);
    }
  };

  const resetRecording = async (): Promise<void> => {
    await cleanup();
    setRecordingState({
      isRecording: false,
      isPaused: false,
      duration: 0,
      uri: null,
    });
    setWebRecording({
      mediaRecorder: null,
      audioChunks: [],
      stream: null,
    });
    setRecording(null);
    setIsRecordingUnloaded(false);
    setIsTranscribing(false);
  };

  return {
    recordingState,
    isTranscribing,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    resetRecording,
  };
};
