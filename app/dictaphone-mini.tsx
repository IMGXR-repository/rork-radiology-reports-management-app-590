import React, { useState, useEffect, useRef } from 'react';
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Platform,
  ActivityIndicator,
} from 'react-native';
import * as Clipboard from 'expo-clipboard';
import { Mic, Square } from 'lucide-react-native';
import { useApp } from '@/contexts/AppContext';
import { lightTheme, darkTheme } from '@/constants/theme';
import { Audio } from 'expo-av';

const BROADCAST_CHANNEL_NAME = 'radia-app-sync';

export default function DictaphoneMiniScreen() {
  const { settings, addSavedTranscription } = useApp();
  const theme = settings?.theme === 'dark' ? darkTheme : lightTheme;

  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [recording, setRecording] = useState<Audio.Recording | null>(null);
  const [isTranscribing, setIsTranscribing] = useState<boolean>(false);
  const [recordingDuration, setRecordingDuration] = useState<number>(0);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const broadcastChannelRef = useRef<BroadcastChannel | null>(null);

  useEffect(() => {
    if (Platform.OS === 'web' && typeof BroadcastChannel !== 'undefined') {
      broadcastChannelRef.current = new BroadcastChannel(BROADCAST_CHANNEL_NAME);
      console.log('üì° [Mini] BroadcastChannel inicializado');
      
      return () => {
        broadcastChannelRef.current?.close();
      };
    }
  }, []);

  const startRecording = async () => {
    try {
      if (Platform.OS === 'web') {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true }).catch((error) => {
          console.error('Error al solicitar permisos de micr√≥fono:', error);
          alert('Permiso de micr√≥fono denegado. Por favor, permite el acceso al micr√≥fono.');
          return null;
        });
        if (!stream) return;
        const recorder = new MediaRecorder(stream);
        const chunks: Blob[] = [];

        recorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            chunks.push(e.data);
          }
        };

        recorder.onstop = async () => {
          const audioBlob = new Blob(chunks, { type: 'audio/webm' });
          stream.getTracks().forEach(track => track.stop());
          await transcribeAudio(audioBlob);
        };

        recorder.start();
        setMediaRecorder(recorder);
        setIsRecording(true);
        setRecordingDuration(0);
      } else {
        const { status } = await Audio.requestPermissionsAsync();
        
        if (status !== 'granted') {
          alert('Se requieren permisos de micr√≥fono para grabar.');
          return;
        }

        await Audio.setAudioModeAsync({
          allowsRecordingIOS: true,
          playsInSilentModeIOS: true,
        });

        const { recording: newRecording } = await Audio.Recording.createAsync({
          android: {
            extension: '.m4a',
            outputFormat: Audio.AndroidOutputFormat.MPEG_4,
            audioEncoder: Audio.AndroidAudioEncoder.AAC,
            sampleRate: 44100,
            numberOfChannels: 2,
            bitRate: 128000,
          },
          ios: {
            extension: '.wav',
            outputFormat: Audio.IOSOutputFormat.LINEARPCM,
            audioQuality: Audio.IOSAudioQuality.HIGH,
            sampleRate: 44100,
            numberOfChannels: 2,
            bitRate: 128000,
            linearPCMBitDepth: 16,
            linearPCMIsBigEndian: false,
            linearPCMIsFloat: false,
          },
          web: {
            mimeType: 'audio/webm',
            bitsPerSecond: 128000,
          },
        });

        setRecording(newRecording);
        setIsRecording(true);
        setRecordingDuration(0);
      }
    } catch (error) {
      console.error('Error starting recording:', error);
      alert('Error al iniciar la grabaci√≥n.');
    }
  };

  const stopRecording = async () => {
    try {
      if (Platform.OS === 'web') {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          mediaRecorder.stop();
        }
        setIsRecording(false);
        setMediaRecorder(null);
      } else {
        if (!recording) return;

        await recording.stopAndUnloadAsync();
        const uri = recording.getURI();
        
        if (uri) {
          await Audio.setAudioModeAsync({
            allowsRecordingIOS: false,
          });
          
          await transcribeRecording(uri);
        }

        setRecording(null);
        setIsRecording(false);
      }
    } catch (error) {
      console.error('Error stopping recording:', error);
      alert('Error al detener la grabaci√≥n.');
    }
  };

  const processVoiceCommandsWithAI = async (text: string): Promise<string> => {
    try {
      const response = await fetch(new URL('/agent/chat', process.env['EXPO_PUBLIC_TOOLKIT_URL'] || 'https://toolkit.rork.com').toString(), {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: [
            {
              role: 'user',
              content: `Eres un asistente especializado en procesar transcripciones de voz m√©dicas en espa√±ol. Tu tarea es:

1. DETECTAR Y APLICAR COMANDOS DE VOZ:
   - "nuevo p√°rrafo" / "nuevo parrafo" / "b√°rrafo" / "barrafo" ‚Üí Insertar doble salto de l√≠nea (\n\n) y capitalizar la siguiente palabra
   - "nueva l√≠nea" / "nueva linea" ‚Üí Insertar salto de l√≠nea (\n) y capitalizar la siguiente palabra
   - "punto" ‚Üí .
   - "coma" ‚Üí ,
   - "punto y coma" ‚Üí ;
   - "dos puntos" ‚Üí :
   - "abrir par√©ntesis" / "abre par√©ntesis" ‚Üí (
   - "cerrar par√©ntesis" / "cierra par√©ntesis" / "cierre par√©ntesis" ‚Üí )
   - "[n√∫mero] por [n√∫mero]" (ej: "3 por 2") ‚Üí [n√∫mero]x[n√∫mero] (ej: 3x2)

2. CORREGIR ERRORES DE TRANSCRIPCI√ìN:
   - Palabras m√©dicas mal transcritas
   - Abreviaciones m√©dicas (ej: "AP" para Anteroposterior, "T" para Transversal, "CC" para Craneocaudal)
   - Unidades de medida (mm, cm, etc.)

3. CAPITALIZACI√ìN:
   - Despu√©s de punto, la siguiente palabra debe empezar en may√∫scula
   - Despu√©s de comandos de "nuevo p√°rrafo" o "nueva l√≠nea", capitalizar la siguiente palabra
   - NO agregar espacios extra al inicio de p√°rrafos nuevos

4. FORMATO:
   - Eliminar espacios antes de puntuaci√≥n
   - Agregar espacio despu√©s de puntuaci√≥n (excepto al final)
   - NO agregar informaci√≥n adicional
   - Mantener el contenido m√©dico exacto

Texto transcrito:
${text}

Devuelve √öNICAMENTE el texto procesado con los comandos aplicados y errores corregidos. Sin explicaciones.`,
            },
          ],
        }),
      });

      if (!response.ok) {
        throw new Error(`Error en procesamiento: ${response.status}`);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('No se pudo leer la respuesta');
      }

      const decoder = new TextDecoder();
      let processedText = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('0:')) {
            try {
              const jsonStr = line.substring(2);
              const data = JSON.parse(jsonStr);
              if (data.type === 'text-delta' && data.textDelta) {
                processedText += data.textDelta;
              }
            } catch (e) {
              console.error('Error parsing chunk:', e);
            }
          }
        }
      }

      return processedText.trim();
    } catch (error) {
      console.error('Error processing with AI:', error);
      return text;
    }
  };

  const processVoiceCommands = (text: string): string => {
    let processed = text;
    
    processed = processed.replace(/\b(\d+)\s+por\s+(\d+)\b/gi, '$1x$2');
    processed = processed.replace(/\bcoma\b/gi, ',');
    processed = processed.replace(/\bpunto\b/gi, '.');
    processed = processed.replace(/\bpunto y coma\b/gi, ';');
    processed = processed.replace(/\bdos puntos\b/gi, ':');
    processed = processed.replace(/\binterrogaci√≥n\b/gi, '?');
    processed = processed.replace(/\bexclamaci√≥n\b/gi, '!');
    processed = processed.replace(/\bgui√≥n\b/gi, '-');
    processed = processed.replace(/\b(abrir|abre)\s+par√©ntesis\b/gi, '(');
    processed = processed.replace(/\b(cerrar|cierra)\s+par√©ntesis\b/gi, ')');
    processed = processed.replace(/\bcomillas\b/gi, '"');
    processed = processed.replace(/\bnuevo\s+(p√°rrafo|parrafo|b√°rrafo|barrafo)\b/gi, '\n\n__CAPITALIZE__');
    processed = processed.replace(/\bnueva\s+(l√≠nea|linea)\b/gi, '\n__CAPITALIZE__');
    processed = processed.replace(/__CAPITALIZE__\s+/g, '__CAPITALIZE__');
    processed = processed.replace(/__CAPITALIZE__(\w)/g, (match, letter) => {
      return letter.toUpperCase();
    });
    processed = processed.replace(/__CAPITALIZE__/g, '');
    processed = processed.replace(/([.!?])\s+(\w)/g, (match, punctuation, letter) => {
      return punctuation + ' ' + letter.toUpperCase();
    });
    processed = processed.replace(/\s+([.,;:?!)])/g, '$1');
    processed = processed.replace(/([.,;:?!])\1+/g, '$1');
    processed = processed.replace(/([.,;:?!])(?!\s|$)/g, '$1 ');
    
    return processed.trim();
  };

  const enhanceTranscription = async (text: string): Promise<string> => {
    try {
      const response = await fetch(new URL('/agent/chat', process.env['EXPO_PUBLIC_TOOLKIT_URL'] || 'https://toolkit.rork.com').toString(), {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: [
            {
              role: 'user',
              content: `Eres un asistente m√©dico experto en procesar transcripciones de informes radiol√≥gicos en espa√±ol. Tu tarea es corregir y formatear el texto transcrito siguiendo estas reglas EN ORDEN EXACTO:

**PASO 1: CORRECCI√ìN DE ERRORES CR√çTICOS DE RECONOCIMIENTO DE VOZ:**
   - "b√°rrafo" / "barrafo" / "novo p√°rrafo" / "nova p√°rrafo" ‚Üí ELIMINAR completamente (es comando de salto de p√°rrafo)
   - "uno" al inicio de frase o despu√©s de punto ‚Üí ELIMINAR (es error del STT)
   - "nova l√≠nea" / "nueva l√≠nea" ‚Üí ELIMINAR completamente
   - "novo" ‚Üí ELIMINAR
   - ", ." ‚Üí "." (eliminar coma antes de punto)
   - " ," ‚Üí "," (eliminar espacio antes de coma)
   - " ." ‚Üí "." (eliminar espacio antes de punto)

**PASO 2: CORRECCI√ìN M√âDICA Y ORTOGR√ÅFICA (CR√çTICO):**
   Corregir t√©rminos m√©dicos mal transcritos:
   - "intraestrep√°tica" / "intrahestepatica" ‚Üí "intrahep√°tica"
   - "biabiliar" / "biabilar" / "via biliar" ‚Üí "v√≠a biliar"
   - "parenchima" ‚Üí "par√©nquima"
   - "litias" ‚Üí "litiasis"
   - "celda pancr√°tica" / "celda pancr√©tica" ‚Üí "celda pancre√°tica"
   - "p√°ncreda" / "pancrea" ‚Üí "p√°ncreas"
   - "ves√≠cula viliar" ‚Üí "ves√≠cula biliar"
   - "viliar" ‚Üí "biliar"
   - "suprarrenales" ‚Üí verificar ortograf√≠a
   - "bazo" ‚Üí verificar contexto

**PASO 3: LIMPIEZA DE PUNTUACI√ìN:**
   - ELIMINAR todas las comas antes de puntos: ", ." ‚Üí "."
   - ELIMINAR espacios antes de puntuaci√≥n: " ," ‚Üí "," y " ." ‚Üí "."
   - Agregar espacio despu√©s de comas si no existe: "," ‚Üí ", "
   - Agregar espacio despu√©s de puntos si no existe: "." ‚Üí ". "
   - NO usar punto y coma (;)
   - Eliminar puntos duplicados: ".." ‚Üí "."
   - Eliminar comas duplicadas: ",," ‚Üí ","

**PASO 4: CAPITALIZACI√ìN:**
   - Primera letra despu√©s de punto SIEMPRE en may√∫scula
   - Primera letra de la primera palabra del texto en may√∫scula
   - Nombres de √≥rganos al inicio de secci√≥n en MAY√öSCULA COMPLETA

**PASO 5: ESTRUCTURA Y FORMATO (CR√çTICO):**
   - Detectar cambios de √≥rgano/estructura anat√≥mica
   - Formato: √ìRGANO: Descripci√≥n.
   - Cada √≥rgano en nueva l√≠nea con l√≠nea en blanco antes
   - Ejemplos de √≥rganos a detectar: h√≠gado, ves√≠cula biliar, v√≠a biliar, bazo, p√°ncreas, ri√±ones, gl√°ndulas suprarrenales, celda pancre√°tica

**PASO 6: COHERENCIA FINAL:**
   - Eliminar todos los espacios dobles: "  " ‚Üí " "
   - Eliminar espacios al inicio de l√≠neas
   - Eliminar l√≠neas vac√≠as m√∫ltiples (m√°ximo 1 l√≠nea en blanco entre secciones)
   - Verificar que no haya comandos de voz residuales

**Texto a procesar:**
${text}

**IMPORTANTE: Devuelve √öNICAMENTE el texto corregido y formateado. Sin explicaciones, sin comentarios adicionales, sin introducci√≥n, solo el informe m√©dico procesado.**`,
            },
          ],
        }),
      });

      if (!response.ok) {
        throw new Error(`Error en mejora: ${response.status}`);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('No se pudo leer la respuesta');
      }

      const decoder = new TextDecoder();
      let enhancedText = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('0:')) {
            try {
              const jsonStr = line.substring(2);
              const data = JSON.parse(jsonStr);
              if (data.type === 'text-delta' && data.textDelta) {
                enhancedText += data.textDelta;
              }
            } catch (e) {
              console.error('Error parsing chunk:', e);
            }
          }
        }
      }

      return enhancedText.trim();
    } catch (error) {
      console.error('Error enhancing transcription:', error);
      return text;
    }
  };

  const transcribeRecording = async (uri: string) => {
    setIsTranscribing(true);
    try {
      const formData = new FormData();
      
      const uriParts = uri.split('.');
      const fileType = uriParts[uriParts.length - 1];
      
      const audioFile = {
        uri,
        name: `recording.${fileType}`,
        type: `audio/${fileType}`,
      } as any;
      
      formData.append('audio', audioFile);
      
      const response = await fetch('https://toolkit.rork.com/stt/transcribe/', {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) {
        throw new Error(`Error en transcripci√≥n: ${response.status}`);
      }
      
      const result = await response.json();
      const rawTranscription = result.text;
      
      const aiProcessedText = await processVoiceCommandsWithAI(rawTranscription);
      const transcription = processVoiceCommands(aiProcessedText);
      const enhancedText = await enhanceTranscription(transcription);
      
      if (enhancedText) {
        await addSavedTranscription(enhancedText, 'ia');
        await Clipboard.setStringAsync(enhancedText);
        
        if (broadcastChannelRef.current) {
          console.log('üì∂ [Mini] Enviando notificaci√≥n de transcripci√≥n (m√≥vil)...');
          broadcastChannelRef.current.postMessage({ type: 'transcription-added' });
        }
      }
    } catch (error) {
      console.error('Error transcribing:', error);
      alert('Error al transcribir el audio.');
    } finally {
      setIsTranscribing(false);
    }
  };

  const transcribeAudio = async (audioBlob: Blob) => {
    setIsTranscribing(true);
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob, 'recording.webm');
      
      const response = await fetch('https://toolkit.rork.com/stt/transcribe/', {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) {
        throw new Error(`Error en transcripci√≥n: ${response.status}`);
      }
      
      const result = await response.json();
      const rawTranscription = result.text;
      
      const aiProcessedText = await processVoiceCommandsWithAI(rawTranscription);
      const transcription = processVoiceCommands(aiProcessedText);
      const enhancedText = await enhanceTranscription(transcription);
      
      if (enhancedText) {
        await addSavedTranscription(enhancedText, 'ia');
        await Clipboard.setStringAsync(enhancedText);
        
        if (broadcastChannelRef.current) {
          console.log('üì∂ [Mini] Enviando notificaci√≥n de transcripci√≥n (web)...');
          broadcastChannelRef.current.postMessage({ type: 'transcription-added' });
        }
      }
    } catch (error) {
      console.error('Error transcribing:', error);
      alert('Error al transcribir el audio.');
    } finally {
      setIsTranscribing(false);
    }
  };



  useEffect(() => {
    let interval: ReturnType<typeof setInterval> | undefined;
    if (isRecording) {
      interval = setInterval(() => {
        setRecordingDuration(prev => prev + 1);
      }, 1000);
    }
    return () => {
      if (interval) clearInterval(interval);
    };
  }, [isRecording]);

  return (
    <View style={[styles.container, { backgroundColor: theme.background }]}>
      <View style={[styles.content, { backgroundColor: 'transparent' }]}>
        <TouchableOpacity
          style={[
            styles.recordButton,
            { backgroundColor: isRecording ? '#FF6B6B' : theme.primary }
          ]}
          onPress={isRecording ? stopRecording : startRecording}
          disabled={isTranscribing}
        >
          {isTranscribing ? (
            <ActivityIndicator size="small" color="#FFFFFF" />
          ) : isRecording ? (
            <Square size={18} color="#FFFFFF" fill="#FFFFFF" />
          ) : (
            <Mic size={18} color="#FFFFFF" />
          )}
        </TouchableOpacity>
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  content: {
    padding: 0,
    alignItems: 'center',
    justifyContent: 'center',
  },
  recordButton: {
    width: 48,
    height: 48,
    borderRadius: 24,
    justifyContent: 'center',
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.25,
    shadowRadius: 3,
    elevation: 5,
  },
});
